{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ROOT\n",
    "import root_numpy as rn\n",
    "from larocv import larocv\n",
    "\n",
    "rse    = ['run','subrun','event']\n",
    "rsev   = ['run','subrun','event','vtxid']\n",
    "rserv  = ['run','subrun','event','roid','vtxid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex data frame\n",
    "dfs  = {}\n",
    "\n",
    "# Event data frame\n",
    "edfs = {}\n",
    "mdfs = {}\n",
    "\n",
    "sample_name0 = \"nue\"\n",
    "sample_file0 = \"comb_ana_nue.root\"\n",
    "\n",
    "sample_name1 = \"cosmic\"\n",
    "sample_file1 = \"comb_ana_cosmic_no_stopmu.root\"\n",
    "\n",
    "\n",
    "for name,file_ in [(sample_name0,sample_file0),\n",
    "                   (sample_name1,sample_file1)]:\n",
    "    \n",
    "    INPUT_FILE  = file_\n",
    "    \n",
    "    #\n",
    "    # Vertex wise Trees\n",
    "    #\n",
    "    vertex_df = pd.DataFrame(rn.root2array(INPUT_FILE,treename='VertexTree'))\n",
    "    angle_df  = pd.DataFrame(rn.root2array(INPUT_FILE,treename='AngleAnalysis'))\n",
    "    shape_df  = pd.DataFrame(rn.root2array(INPUT_FILE,treename='ShapeAnalysis'))\n",
    "    gap_df    = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"GapAnalysis\"))\n",
    "    match_df  = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"MatchAnalysis\"))\n",
    "    dqds_df   = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"dQdSAnalysis\"))\n",
    "\n",
    "    #\n",
    "    # Combine DataFrames\n",
    "    #\n",
    "    comb_df = pd.concat([vertex_df.set_index(rserv),\n",
    "                         angle_df.set_index(rserv),\n",
    "                         shape_df.set_index(rserv),\n",
    "                         gap_df.set_index(rserv),\n",
    "                         angle_df.set_index(rserv),\n",
    "                         match_df.set_index(rserv),\n",
    "                         dqds_df.set_index(rserv)],axis=1)\n",
    "\n",
    "    comb_df = comb_df.reset_index()\n",
    "    event_vertex_df   = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"EventVertexTree\"))\n",
    "\n",
    "    def drop_y(df):\n",
    "        to_drop = [x for x in df if x.endswith('_y')]\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        \n",
    "    comb_df = comb_df.set_index(rse).join(event_vertex_df.set_index(rse),how='outer',lsuffix='',rsuffix='_y').reset_index()\n",
    "    drop_y(comb_df)\n",
    "    \n",
    "    if name == \"nue\":\n",
    "        nufilter_df       = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"NuFilterTree\"))\n",
    "        mc_df             = pd.DataFrame(rn.root2array(INPUT_FILE,treename=\"MCTree\"))\n",
    "        \n",
    "        comb_df = comb_df.set_index(rse).join(nufilter_df.set_index(rse),how='outer',lsuffix='',rsuffix='_y').reset_index()\n",
    "        drop_y(comb_df)    \n",
    "        \n",
    "        comb_df = comb_df.set_index(rse).join(mc_df.set_index(rse),how='outer',lsuffix='',rsuffix='_y').reset_index()\n",
    "        drop_y(comb_df)\n",
    "        \n",
    "        tmp = pd.DataFrame(rn.root2array(\"nue_cosmo_ana.root\",treename='EventCosmicPixelTree'))\n",
    "        comb_df = comb_df.set_index(rse).join(tmp.set_index(rse),how='outer',lsuffix='',rsuffix='_y').reset_index()\n",
    "        drop_y(comb_df)\n",
    "        \n",
    "\n",
    "    #\n",
    "    # Store vertex wise data frame\n",
    "    #\n",
    "    comb_df = comb_df.reset_index()\n",
    "    comb_df = comb_df.loc[:,~comb_df.columns.duplicated()]\n",
    "    \n",
    "    comb_df['cvtxid'] = 0.0\n",
    "    \n",
    "    def func(group):\n",
    "        group['cvtxid'] = np.arange(0,group['cvtxid'].size)\n",
    "        return group\n",
    "\n",
    "    comb_df = comb_df.groupby(['run','subrun','event']).apply(func)\n",
    "    \n",
    "    dfs[name] = comb_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_shower_assumption(df):\n",
    "    df['trkid'] = df.apply(lambda x : 0 if(x['par1_type']==1) else 1,axis=1)\n",
    "    df['shrid'] = df.apply(lambda x : 1 if(x['par2_type']==2) else 0,axis=1)\n",
    "    \n",
    "    df['trk_frac_avg'] = df.apply(lambda x : x['par1_frac'] if(x['par1_type']==1) else x['par2_frac'],axis=1)\n",
    "    df['shr_frac_avg'] = df.apply(lambda x : x['par2_frac'] if(x['par2_type']==2) else x['par1_frac'],axis=1)\n",
    "\n",
    "ts_mdf_m = {}\n",
    "\n",
    "for name, comb_df in dfs.copy().iteritems():\n",
    "    print\n",
    "    print \"@ sample\",name\n",
    "    print\n",
    "    \n",
    "    ts_mdf = comb_df.copy()\n",
    "\n",
    "    print \"Asking nue assumption\"\n",
    "    print \"Asking npar==2\"\n",
    "    print \"Asking in_fiducial==1\"\n",
    "    print \"Asking pathexists2==1\"\n",
    "\n",
    "    ts_mdf = ts_mdf.query(\"npar==2\")\n",
    "    track_shower_assumption(ts_mdf)\n",
    "    ts_mdf = ts_mdf.query(\"par1_type != par2_type\")\n",
    "    ts_mdf = ts_mdf.query(\"in_fiducial==1\")\n",
    "    ts_mdf = ts_mdf.query(\"pathexists2==1\")\n",
    "\n",
    "    \n",
    "    #\n",
    "    # SSNet Fraction\n",
    "    #\n",
    "    ts_mdf['trk_frac'] = ts_mdf.apply(lambda x : x['trk_frac_avg'] / x['nplanes_v'][x['trkid']],axis=1) \n",
    "    ts_mdf['shr_frac'] = ts_mdf.apply(lambda x : x['shr_frac_avg'] / x['nplanes_v'][x['shrid']],axis=1) \n",
    "    \n",
    "    #\n",
    "    # PCA\n",
    "    #\n",
    "    \n",
    "    ts_mdf['cosangle3d']=ts_mdf.apply(lambda x : larocv.CosOpeningAngle(x['par_trunk_pca_theta_estimate_v'][0],\n",
    "                                                                        x['par_trunk_pca_phi_estimate_v'][0],\n",
    "                                                                        x['par_trunk_pca_theta_estimate_v'][1],\n",
    "                                                                        x['par_trunk_pca_phi_estimate_v'][1]),axis=1)\n",
    "    \n",
    "    ts_mdf['angle3d'] = ts_mdf.apply(lambda x : np.arccos(x['cosangle3d']),axis=1)\n",
    "    \n",
    "    \n",
    "    ts_mdf['shr_trunk_pca_theta_estimate'] = ts_mdf.apply(lambda x : x['par_trunk_pca_theta_estimate_v'][x['shrid']],axis=1) \n",
    "    ts_mdf['trk_trunk_pca_theta_estimate'] = ts_mdf.apply(lambda x : x['par_trunk_pca_theta_estimate_v'][x['trkid']],axis=1) \n",
    "    \n",
    "    ts_mdf['shr_trunk_pca_cos_theta_estimate'] = ts_mdf.apply(lambda x : np.cos(x['par_trunk_pca_theta_estimate_v'][x['shrid']]),axis=1) \n",
    "    ts_mdf['trk_trunk_pca_cos_theta_estimate'] = ts_mdf.apply(lambda x : np.cos(x['par_trunk_pca_theta_estimate_v'][x['trkid']]),axis=1) \n",
    "\n",
    "    \n",
    "    #\n",
    "    # 3D\n",
    "    #\n",
    "    ts_mdf['shr_3d_length'] = ts_mdf.apply(lambda x : x['par_pca_end_len_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['trk_3d_length'] = ts_mdf.apply(lambda x : x['par_pca_end_len_v'][x['trkid']],axis=1)\n",
    "\n",
    "    ts_mdf['shr_3d_QavgL'] = ts_mdf.apply(lambda x : x['qsum_v'][x['shrid']] / x['par_pca_end_len_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['trk_3d_QavgL'] = ts_mdf.apply(lambda x : x['qsum_v'][x['trkid']] / x['par_pca_end_len_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    # Max deflection\n",
    "    #\n",
    "    ts_mdf['shr_triangle_d_max'] = ts_mdf.apply(lambda x : x['triangle_d_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['trk_triangle_d_max'] = ts_mdf.apply(lambda x : x['triangle_d_max_v'][x['trkid']],axis=1)\n",
    "    \n",
    "    #\n",
    "    # Mean pixel dist from 2D PCA\n",
    "    #\n",
    "    ts_mdf['shr_mean_pixel_dist'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_v'][x['shrid']]/x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_mean_pixel_dist_max'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_mean_pixel_dist_min'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_mean_pixel_dist_ratio'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_min_v'][x['shrid']] / x['mean_pixel_dist_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_mean_pixel_dist'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_v'][x['trkid']]/x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_mean_pixel_dist_max'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_mean_pixel_dist_min'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_min_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_mean_pixel_dist_ratio'] = ts_mdf.apply(lambda x : x['mean_pixel_dist_min_v'][x['trkid']] / x['mean_pixel_dist_max_v'][x['trkid']],axis=1)     \n",
    "\n",
    "    #\n",
    "    # Sigma pixel dist from 2D PCA\n",
    "    #\n",
    "    ts_mdf['shr_sigma_pixel_dist']       = ts_mdf.apply(lambda x : x['sigma_pixel_dist_v'][x['shrid']]/x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_sigma_pixel_dist_max']   = ts_mdf.apply(lambda x : x['sigma_pixel_dist_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_sigma_pixel_dist_min']   = ts_mdf.apply(lambda x : x['sigma_pixel_dist_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_sigma_pixel_dist_ratio'] = ts_mdf.apply(lambda x : x['sigma_pixel_dist_min_v'][x['shrid']] / x['sigma_pixel_dist_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_sigma_pixel_dist']       = ts_mdf.apply(lambda x : x['sigma_pixel_dist_v'][x['trkid']]/x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_sigma_pixel_dist_max']   = ts_mdf.apply(lambda x : x['sigma_pixel_dist_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_sigma_pixel_dist_min']   = ts_mdf.apply(lambda x : x['sigma_pixel_dist_min_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_sigma_pixel_dist_ratio'] = ts_mdf.apply(lambda x : x['sigma_pixel_dist_min_v'][x['trkid']] / x['sigma_pixel_dist_max_v'][x['trkid']],axis=1)    \n",
    "\n",
    "    #\n",
    "    # Ratio of # num pixels\n",
    "    #\n",
    "    ts_mdf['shr_par_pixel_ratio'] = ts_mdf.apply(lambda x : x['par_pixel_ratio_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['trk_par_pixel_ratio'] = ts_mdf.apply(lambda x : x['par_pixel_ratio_v'][x['trkid']],axis=1) \n",
    "\n",
    "    #\n",
    "    # 2D angle difference @ vertex\n",
    "    #\n",
    "    ts_mdf['anglediff0'] = ts_mdf['anglediff'].values \n",
    "\n",
    "    #\n",
    "    # 2D length\n",
    "    #\n",
    "    ts_mdf['shr_avg_length']   = ts_mdf.apply(lambda x : x['length_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_length_min']   = ts_mdf.apply(lambda x : x['length_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_length_max']   = ts_mdf.apply(lambda x : x['length_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_length_ratio'] = ts_mdf.apply(lambda x : x['length_min_v'][x['shrid']] / x['length_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_avg_length']   = ts_mdf.apply(lambda x : x['length_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_length_min']   = ts_mdf.apply(lambda x : x['length_min_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_length_max']   = ts_mdf.apply(lambda x : x['length_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_length_ratio'] = ts_mdf.apply(lambda x : x['length_min_v'][x['trkid']] / x['length_max_v'][x['trkid']],axis=1)\n",
    "    \n",
    "    #\n",
    "    # 2D width\n",
    "    #\n",
    "    ts_mdf['shr_avg_width']   = ts_mdf.apply(lambda x : x['width_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_width_min']   = ts_mdf.apply(lambda x : x['width_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_width_max']   = ts_mdf.apply(lambda x : x['width_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_width_ratio'] = ts_mdf.apply(lambda x : x['width_min_v'][x['shrid']] / x['width_max_v'][x['shrid']],axis=1)\n",
    "\n",
    "    ts_mdf['trk_avg_width']   = ts_mdf.apply(lambda x : x['width_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_width_max']   = ts_mdf.apply(lambda x : x['width_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_width_min']   = ts_mdf.apply(lambda x : x['width_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_width_ratio'] = ts_mdf.apply(lambda x : x['width_min_v'][x['trkid']] / x['width_max_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    # 2D perimeter\n",
    "    #\n",
    "    ts_mdf['shr_avg_perimeter'] = ts_mdf.apply(lambda x : x['perimeter_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_perimeter_min'] = ts_mdf.apply(lambda x : x['perimeter_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_perimeter_max'] = ts_mdf.apply(lambda x : x['perimeter_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_perimeter_ratio'] = ts_mdf.apply(lambda x : x['perimeter_min_v'][x['shrid']] / x['perimeter_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_avg_perimeter'] = ts_mdf.apply(lambda x : x['perimeter_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_perimeter_min'] = ts_mdf.apply(lambda x : x['perimeter_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_perimeter_max'] = ts_mdf.apply(lambda x : x['perimeter_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_perimeter_ratio'] = ts_mdf.apply(lambda x : x['perimeter_min_v'][x['trkid']] / x['perimeter_max_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    # 2D area\n",
    "    #\n",
    "    ts_mdf['shr_avg_area'] = ts_mdf.apply(lambda x : x['area_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_area_min'] = ts_mdf.apply(lambda x : x['area_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_area_max'] = ts_mdf.apply(lambda x : x['area_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_area_ratio'] = ts_mdf.apply(lambda x : x['area_min_v'][x['shrid']] / x['area_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_avg_area'] = ts_mdf.apply(lambda x : x['area_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_area_min'] = ts_mdf.apply(lambda x : x['area_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_area_max'] = ts_mdf.apply(lambda x : x['area_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_area_ratio'] = ts_mdf.apply(lambda x : x['area_min_v'][x['trkid']] / x['area_max_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    # N pixel\n",
    "    #\n",
    "    ts_mdf['shr_avg_npixel'] = ts_mdf.apply(lambda x : x['npixel_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_npixel_min'] = ts_mdf.apply(lambda x : x['npixel_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_npixel_max'] = ts_mdf.apply(lambda x : x['npixel_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_npixel_ratio'] = ts_mdf.apply(lambda x : x['npixel_min_v'][x['shrid']] / x['npixel_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_avg_npixel'] = ts_mdf.apply(lambda x : x['npixel_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_npixel_min'] = ts_mdf.apply(lambda x : x['npixel_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_npixel_max'] = ts_mdf.apply(lambda x : x['npixel_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_npixel_ratio'] = ts_mdf.apply(lambda x : x['npixel_min_v'][x['trkid']] / x['npixel_max_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    # Q sum\n",
    "    #\n",
    "    ts_mdf['shr_avg_qsum']   = ts_mdf.apply(lambda x : x['qsum_v'][x['shrid']] / x['nplanes_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_qsum_min']   = ts_mdf.apply(lambda x : x['qsum_min_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_qsum_max']   = ts_mdf.apply(lambda x : x['qsum_max_v'][x['shrid']],axis=1)\n",
    "    ts_mdf['shr_qsum_ratio'] = ts_mdf.apply(lambda x : x['qsum_min_v'][x['shrid']] / x['qsum_max_v'][x['shrid']],axis=1)\n",
    "    \n",
    "    ts_mdf['trk_avg_qsum']   = ts_mdf.apply(lambda x : x['qsum_v'][x['trkid']] / x['nplanes_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_qsum_min']   = ts_mdf.apply(lambda x : x['qsum_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_qsum_max']   = ts_mdf.apply(lambda x : x['qsum_max_v'][x['trkid']],axis=1)\n",
    "    ts_mdf['trk_qsum_ratio'] = ts_mdf.apply(lambda x : x['qsum_min_v'][x['trkid']] / x['qsum_max_v'][x['trkid']],axis=1)\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    ts_mdf_m[name] = ts_mdf.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='nue'\n",
    "print \"~~~~~~~~~ Raw Output ~~~~~~~~~\"\n",
    "all_df   = dfs[name]\n",
    "event_df = dfs[name].groupby(rse).nth(0) \n",
    "\n",
    "scedr=5\n",
    "print \"Loaded events...........\",event_df.index.size\n",
    "print \"...good cROI counter....\",event_df.query(\"good_croi_ctr>0\").index.size\n",
    "print \"...reco.................\",event_df.query(\"num_vertex>0\").index.size\n",
    "print\n",
    "if name=='nue':\n",
    "    print \"1L1P....................\",event_df.query(\"selected1L1P==1\").index.size\n",
    "    print \"...good cROI counter....\",event_df.query(\"good_croi_ctr>0 & selected1L1P==1\").index.size\n",
    "    print \"...reco.................\",event_df.query(\"good_croi_ctr>0 & selected1L1P==1 & num_vertex>0\").dropna().index.size\n",
    "    print\n",
    "    print \"1L1P E in [200,800] MeV.\",event_df.query(\"selected1L1P==1 & energyInit>=200 & energyInit<=800\").index.size\n",
    "    print \"...good cROI counter....\",event_df.query(\"selected1L1P==1 & good_croi_ctr>0 & energyInit>=200 & energyInit<=800\").index.size\n",
    "    print \"...reco.................\",event_df.query(\"selected1L1P==1 & good_croi_ctr>0 & energyInit>=200 & energyInit<=800 & num_vertex>0\").dropna().index.size\n",
    "    print\n",
    "    print \"===> GOOD vertices scedr<{} <===\".format(scedr)\n",
    "    SS=\"scedr<@scedr\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "    print \">>>good cROI<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print \n",
    "    print \">>>good cROI + 1L1P<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "    print \">>>good cROI + 1L1P + E<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1 & energyInit>=200 & energyInit<=800\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "\n",
    "if name=='cosmic':\n",
    "    print \"===> Total Vertices <===\".format(scedr)\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").groupby(rse))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='nue'\n",
    "print \"~~~~~~~~~ Nue Assumption Output ~~~~~~~~~\"\n",
    "all_df   = ts_mdf_m[name]\n",
    "event_df = dfs[name].groupby(rse).nth(0) \n",
    "\n",
    "scedr=5\n",
    "print \"Loaded events...........\",event_df.index.size\n",
    "print \"...good cROI counter....\",event_df.query(\"good_croi_ctr>0\").index.size\n",
    "print \"...reco.................\",event_df.query(\"num_vertex>0\").index.size\n",
    "print\n",
    "if name == 'nue':\n",
    "    print \"1L1P....................\",event_df.query(\"selected1L1P==1\").index.size\n",
    "    print \"...good cROI counter....\",event_df.query(\"good_croi_ctr>0 & selected1L1P==1\").index.size\n",
    "    print \"...reco.................\",event_df.query(\"good_croi_ctr>0 & selected1L1P==1 & num_vertex>0\").dropna().index.size\n",
    "    print\n",
    "    print \"1L1P E in [200,800] MeV.\",event_df.query(\"selected1L1P==1 & energyInit>=200 & energyInit<=800\").index.size\n",
    "    print \"...good cROI counter....\",event_df.query(\"selected1L1P==1 & good_croi_ctr>0 & energyInit>=200 & energyInit<=800\").index.size\n",
    "    print \"...reco.................\",event_df.query(\"selected1L1P==1 & good_croi_ctr>0 & energyInit>=200 & energyInit<=800 & num_vertex>0\").dropna().index.size\n",
    "    print\n",
    "    print \"===> GOOD vertices scedr<{} <===\".format(scedr)\n",
    "    SS=\"scedr<@scedr\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "    print \">>>good cROI<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print \n",
    "    print \">>>good cROI + 1L1P<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "    print \">>>good cROI + 1L1P + E<<<\"\n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1 & energyInit>=200 & energyInit<=800\"\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").query(SS).index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").query(SS).groupby(rse))\n",
    "    print\n",
    "if name=='cosmic':\n",
    "    print \"===> Total Vertices <===\".format(scedr)\n",
    "    print \"...total................\",all_df.query(\"num_vertex>0\").index.size\n",
    "    print \"...events...............\",len(all_df.query(\"num_vertex>0\").groupby(rse))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "pdf_m = collections.OrderedDict()\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 40.0\n",
    "# dx = 2\n",
    "# pdf_m['shr_triangle_d_max'] = ((xlo,xhi,dx),\"Shower - Max 2D Deflection [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 40.0\n",
    "# dx = 2\n",
    "# pdf_m['trk_triangle_d_max'] = ((xlo,xhi,dx),\"Track - Max 2D Deflection [pix]\")\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "xlo= 0.0\n",
    "xhi= 10.0\n",
    "dx = 0.2\n",
    "pdf_m['shr_mean_pixel_dist'] = ((xlo,xhi,dx),\"Shower - Mean Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['trk_mean_pixel_dist'] = ((xlo,xhi,dx),\"Track - Mean Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['shr_mean_pixel_dist_max'] = ((xlo,xhi,dx),\"Shower - Max Mean Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['trk_mean_pixel_dist_max'] = ((xlo,xhi,dx),\"Track - Max Mean Distance from 2D PCA [pix]\")\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "xlo= 0.0\n",
    "xhi= 10.0\n",
    "dx = 0.2\n",
    "pdf_m['shr_sigma_pixel_dist'] = ((xlo,xhi,dx),\"Shower - Sigma Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['trk_sigma_pixel_dist'] = ((xlo,xhi,dx),\"Track - Sigma Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['shr_sigma_pixel_dist_max'] = ((xlo,xhi,dx),\"Shower - Max Sigma Distance from 2D PCA [pix]\")\n",
    "\n",
    "# xlo= 0.0\n",
    "# xhi= 10.0\n",
    "# dx = 0.2\n",
    "# pdf_m['trk_sigma_pixel_dist_max'] = ((xlo,xhi,dx),\"Track - Max Sigma Distance from 2D PCA [pix]\")\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "xlo= 0.0\n",
    "xhi= 1.0\n",
    "dx = 0.025\n",
    "pdf_m['shr_par_pixel_ratio'] = ((xlo,xhi,dx),\"Shower - Cluster Size Ratio\")\n",
    "\n",
    "xlo= 0.0\n",
    "xhi= 1.0\n",
    "dx = 0.025\n",
    "pdf_m['trk_par_pixel_ratio'] = ((xlo,xhi,dx),\"Track - Cluster Size Ratio\")\n",
    "\n",
    "xlo=-1.0\n",
    "xhi= 1.0\n",
    "dx = 0.05\n",
    "pdf_m['cosangle3d'] = ((xlo,xhi,dx),\"Cos 3D Opening Angle\")\n",
    "\n",
    "#xlo= 0\n",
    "#xhi= 3.14159\n",
    "#dx = 3.14159/40.0\n",
    "#pdf_m['angle3d'] = ((xlo,xhi,dx),\"3D Opening Angle\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 180\n",
    "dx = 5\n",
    "pdf_m['anglediff0'] = ((xlo,xhi,dx),\"2D Angle Difference [deg]\")\n",
    "\n",
    "xlo=-1.0\n",
    "xhi= 1.0\n",
    "dx = 0.05\n",
    "pdf_m['shr_trunk_pca_cos_theta_estimate'] = ((xlo,xhi,dx),\"Shower - Cos 3D Beam Angle\")\n",
    "\n",
    "xlo=-1.0\n",
    "xhi= 1.0\n",
    "dx = 0.05\n",
    "pdf_m['trk_trunk_pca_cos_theta_estimate'] = ((xlo,xhi,dx),\"Track - Cos 3D Beam Angle\")\n",
    "\n",
    "#xlo= 0\n",
    "#xhi= 3.14159\n",
    "#dx = 3.14159/40.0\n",
    "#pdf_m['trk_trunk_pca_theta_estimate'] = ((xlo,xhi,dx),\"Track - 3D Beam Angle\")\n",
    "\n",
    "#xlo= 0\n",
    "#xhi= 3.14159\n",
    "#dx = 3.14159/40.0\n",
    "#pdf_m['shr_trunk_pca_theta_estimate'] = ((xlo,xhi,dx),\"Shower - 3D Beam Angle\")\n",
    "\n",
    "\n",
    "#\n",
    "# Length\n",
    "#\n",
    "xlo= 0\n",
    "xhi= 500\n",
    "dx = 10\n",
    "pdf_m['shr_avg_length'] = ((xlo,xhi,dx),\"Shower - Average 2D Length [pix]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 500\n",
    "dx = 10\n",
    "pdf_m['trk_avg_length'] = ((xlo,xhi,dx),\"Track - Average 2D Length [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['shr_length_min'] = ((xlo,xhi,dx),\"Shower - Min 2D Length [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['trk_length_min'] = ((xlo,xhi,dx),\"Track - Min 2D Length [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['shr_length_max'] = ((xlo,xhi,dx),\"Shower - Max 2D Length [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['trk_length_max'] = ((xlo,xhi,dx),\"Track - Max 2D Length [pix]\")\n",
    "\n",
    "\n",
    "#\n",
    "# Area\n",
    "#\n",
    "xlo= 0\n",
    "xhi= 1000\n",
    "dx = 20\n",
    "pdf_m['shr_avg_area'] = ((xlo,xhi,dx),\"Shower - Average 2D Area [pix^2]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 1000\n",
    "dx = 20\n",
    "pdf_m['trk_avg_area'] = ((xlo,xhi,dx),\"Track - Average 2D Area [pix^2]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['shr_area_min'] = ((xlo,xhi,dx),\"Shower - Min 2D Area [pix^2]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['trk_area_min'] = ((xlo,xhi,dx),\"Track - Min 2D Area [pix^2]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['shr_area_max'] = ((xlo,xhi,dx),\"Shower - Max 2D Area [pix^2]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['trk_area_max'] = ((xlo,xhi,dx),\"Track - Max 2D Area [pix^2]\")\n",
    "\n",
    "#\n",
    "# 3D length\n",
    "#\n",
    "xlo= 0\n",
    "xhi= 100\n",
    "dx = 2\n",
    "pdf_m['shr_3d_length'] = ((xlo,xhi,dx),\"Shower - 3D Length [cm]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 100\n",
    "dx = 2\n",
    "pdf_m['trk_3d_length'] = ((xlo,xhi,dx),\"Track - 3D Length [cm]\")\n",
    "\n",
    "#\n",
    "# Width\n",
    "#\n",
    "\n",
    "xlo= 0\n",
    "xhi= 50\n",
    "dx = 1\n",
    "pdf_m['shr_avg_width'] = ((xlo,xhi,dx),\"Shower - Average 2D Width [px]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 50\n",
    "dx = 1\n",
    "pdf_m['trk_avg_width'] = ((xlo,xhi,dx),\"Track - Average 2D Width [px]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 50\n",
    "# dx = 2\n",
    "# pdf_m['shr_width_min'] = ((xlo,xhi,dx),\"Shower - Min 2D Width [px]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 50\n",
    "# dx = 2\n",
    "# pdf_m['trk_width_min'] = ((xlo,xhi,dx),\"Track - Min 2D Width [px]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 50\n",
    "# dx = 2\n",
    "# pdf_m['shr_width_max'] = ((xlo,xhi,dx),\"Shower - Max 2D Width [px]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 50\n",
    "# dx = 2\n",
    "# pdf_m['trk_width_max'] = ((xlo,xhi,dx),\"Track - Max 2D Width [px]\")\n",
    "\n",
    "\n",
    "#\n",
    "# npixel\n",
    "#\n",
    "# xlo= 0\n",
    "# xhi= 1000\n",
    "# dx = 20\n",
    "# pdf_m['shr_avg_npixel'] = ((xlo,xhi,dx),\"Shower - Average Num. Pixel\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1000\n",
    "# dx = 20\n",
    "# pdf_m['trk_avg_npixel'] = ((xlo,xhi,dx),\"Track - Average Num. Pixel\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['shr_npixel_min'] = ((xlo,xhi,dx),\"Shower - Min Num. Pixel\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['trk_npixel_min'] = ((xlo,xhi,dx),\"Track - Min Num. Pixel\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['shr_npixel_max'] = ((xlo,xhi,dx),\"Shower - Max Num. Pixel\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 600\n",
    "# dx = 10\n",
    "# pdf_m['trk_npixel_max'] = ((xlo,xhi,dx),\"Track - Max Num. Pixel\")\n",
    "\n",
    "#\n",
    "# Perimeter\n",
    "#\n",
    "#xlo= 0\n",
    "#xhi= 300\n",
    "#dx = 5\n",
    "#pdf_m['shr_avg_perimeter'] = ((xlo,xhi,dx),\"Shower - Average 2D Perimeter [pix]\")\n",
    "\n",
    "#xlo= 0\n",
    "#xhi= 300\n",
    "#dx = 5\n",
    "#pdf_m['trk_avg_perimeter'] = ((xlo,xhi,dx),\"Track - Average 2D Perimeter [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['shr_perimeter_min'] = ((xlo,xhi,dx),\"Shower - Min 2D Perimeter [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['trk_perimeter_min'] = ((xlo,xhi,dx),\"Track - Min 2D Perimeter [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['shr_perimeter_min'] = ((xlo,xhi,dx),\"Shower - Max 2D Perimeter [pix]\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 300\n",
    "# dx = 5\n",
    "# pdf_m['trk_perimeter_min'] = ((xlo,xhi,dx),\"Track - Max 2D Perimeter [pix]\")\n",
    "\n",
    "#\n",
    "# Qaverage/L\n",
    "#\n",
    "\n",
    "xlo= 0\n",
    "xhi= 5000\n",
    "dx = 50\n",
    "pdf_m['shr_3d_QavgL'] = ((xlo,xhi,dx),\"Shower - Average Charge / 3D Length [pix/cm]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 5000\n",
    "dx = 50\n",
    "pdf_m['trk_3d_QavgL'] = ((xlo,xhi,dx),\"Track - Average Charge / 3D Length [pix/cm]\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 1\n",
    "dx = 0.025\n",
    "pdf_m['dqds_ratio_01'] = ((xlo,xhi,dx),\"dQ/dX Ratio\")\n",
    "\n",
    "xlo= 0\n",
    "xhi= 500\n",
    "dx = 10\n",
    "pdf_m['dqds_diff_01'] = ((xlo,xhi,dx), \"dQ/dX Difference [pix/cm]\" )\n",
    "\n",
    "xlo= 0.5\n",
    "xhi= 1\n",
    "dx = 0.01\n",
    "pdf_m['trk_frac'] = ((xlo,xhi,dx),\"Track Frac\")\n",
    "\n",
    "xlo= 0.5\n",
    "xhi= 1\n",
    "dx = 0.01\n",
    "pdf_m['shr_frac'] = ((xlo,xhi,dx), \"Shower Frac\" )\n",
    "\n",
    "\n",
    "# #Length\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['shr_length_ratio'] = ((xlo,xhi,dx),\"shr_length_ratio\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['trk_length_ratio'] = ((xlo,xhi,dx),\"trk_length_ratio\")\n",
    "\n",
    "\n",
    "# #Width\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['shr_width_ratio'] = ((xlo,xhi,dx),\"shr_width_ratio\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['trk_width_ratio'] = ((xlo,xhi,dx),\"trk_width_ratio\")\n",
    "\n",
    "\n",
    "# #Area\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['shr_area_ratio'] = ((xlo,xhi,dx),\"shr_area_ratio\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['trk_area_ratio'] = ((xlo,xhi,dx),\"trk_area_ratio\")\n",
    "\n",
    "#qsum\n",
    "# xlo= 0\n",
    "# xhi= 100000\n",
    "# dx = 1000\n",
    "# pdf_m['shr_qsum_max'] = ((xlo,xhi,dx),\"shr_qsum_max\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 100000\n",
    "# dx = 1000\n",
    "# pdf_m['trk_qsum_max'] = ((xlo,xhi,dx),\"trk_qsum_max\")\n",
    "\n",
    "# #area\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['shr_perimeter_ratio'] = ((xlo,xhi,dx),\"shr_perimeter_ratio\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['trk_perimeter_ratio'] = ((xlo,xhi,dx),\"trk_perimeter_ratio\")\n",
    "\n",
    "# #area\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['shr_npixel_ratio'] = ((xlo,xhi,dx),\"shr_npixel_ratio\")\n",
    "\n",
    "# xlo= 0\n",
    "# xhi= 1.0\n",
    "# dx = 0.025\n",
    "# pdf_m['trk_npixel_ratio'] = ((xlo,xhi,dx),\"trk_npixel_ratio\")\n",
    "\n",
    "sig_spectrum_m = {}\n",
    "bkg_spectrum_m = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAW=True\n",
    "\n",
    "for key,item in pdf_m.items():\n",
    "    xlo,xhi,dx = item[0]\n",
    "    name       = item[1]\n",
    "    \n",
    "    SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1\"\n",
    "    \n",
    "    ts_mdf0 = ts_mdf_m['nue'].query(SS).copy()\n",
    "    ts_mdf1 = ts_mdf_m['cosmic'].copy()\n",
    "    \n",
    "    data0 = ts_mdf0[key].values\n",
    "    data0 = data0[data0 >= xlo]\n",
    "    data0 = data0[data0 <= xhi]\n",
    "    \n",
    "    data1 = ts_mdf1[key].values\n",
    "    data1 = data1[data1 >= xlo]\n",
    "    data1 = data1[data1 <= xhi]\n",
    "    \n",
    "    bkg_h = np.histogram(data1,bins=np.arange(xlo,xhi+dx,dx))\n",
    "    sig_h = np.histogram(data0,bins=np.arange(xlo,xhi+dx,dx))\n",
    "       \n",
    "    bkg = bkg_h[0]\n",
    "    sig = sig_h[0]\n",
    "    \n",
    "    bkg = np.where(bkg==0,1,bkg)\n",
    "    sig = np.where(sig==0,1,sig)\n",
    "    \n",
    "    centers=bkg_h[1] + (bkg_h[1][1] - bkg_h[1][0]) / 2.0\n",
    "    centers = centers[:-1]\n",
    "    \n",
    "    bkg_norm = bkg / float(bkg.sum())\n",
    "    sig_norm = sig / float(sig.sum())\n",
    "   \n",
    "    bkg_err = np.sqrt(bkg)\n",
    "    sig_err = np.sqrt(sig)\n",
    "\n",
    "    bkg_err_norm = bkg_err /float(bkg.sum())\n",
    "    sig_err_norm = sig_err /float(sig.sum())\n",
    "    \n",
    "    bkg_spectrum_m[key] = (centers,bkg_norm)\n",
    "    sig_spectrum_m[key] = (centers,sig_norm)\n",
    "\n",
    "    if DRAW: \n",
    "        fig,ax=plt.subplots(figsize=(10,6))\n",
    "        data = bkg_h[1][:-1]\n",
    "        bins = bkg_h[1]\n",
    "        centers = data + (data[1] - data[0])/2.0\n",
    "        \n",
    "        ax.hist(data,bins=bins,weights=bkg_norm,histtype='stepfilled',color='red',lw=1,alpha=0.1)\n",
    "        ax.hist(data,bins=bins,weights=bkg_norm,histtype='step',color='red',lw=2,label='Background')\n",
    "\n",
    "        ax.hist(data,bins=bins,weights=sig_norm,histtype='stepfilled',color='blue',lw=1,alpha=0.1)\n",
    "        ax.hist(data,bins=bins,weights=sig_norm,histtype='step',color='blue',lw=2,label='Signal')\n",
    "\n",
    "        ax.errorbar(centers,bkg_norm,yerr=bkg_err_norm,fmt='o',color='red',markersize=0,lw=2)\n",
    "        ax.errorbar(centers,sig_norm,yerr=sig_err_norm,fmt='o',color='blue',markersize=0,lw=2)\n",
    "    \n",
    "        ax.set_ylabel(\"Fraction of Vertices\",fontweight='bold',fontsize=20)\n",
    "        ax.set_xlabel(name,fontweight='bold',fontsize=20)\n",
    "        ax.set_xlim(xlo,xhi)\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_id(spectrum,value):\n",
    "    return np.argmin(np.abs(spectrum - value))\n",
    "\n",
    "def nearest_id_v(spectrum_v,value_v):\n",
    "    return np.array([np.argmin(np.abs(spectrum[0] - value)) for spectrum, value in zip(spectrum_v,value_v)])\n",
    "\n",
    "def LL(row):\n",
    "    cols = row[sig_spectrum_m.keys()]\n",
    "    sig_res = nearest_id_v(sig_spectrum_m.values(),cols.values)\n",
    "    bkg_res = nearest_id_v(bkg_spectrum_m.values(),cols.values)\n",
    "    \n",
    "    sig_res = np.array([spectrum[1][v] for spectrum,v in zip(sig_spectrum_m.values(),sig_res)])\n",
    "    bkg_res = np.array([spectrum[1][v] for spectrum,v in zip(bkg_spectrum_m.values(),bkg_res)])\n",
    "    \n",
    "    LL = np.log( sig_res / (sig_res + bkg_res) )\n",
    "    return LL.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mdf_pass = {}\n",
    "for name, comb_cut_df in ts_mdf_m.iteritems():\n",
    "    comb_cut_df_copy = comb_cut_df.copy()\n",
    "    comb_cut_df_copy['LL'] = comb_cut_df_copy.apply(LL,axis=1)\n",
    "\n",
    "    print \"Choosing vertex with max LL @name={}\".format(name)\n",
    "    passed_df = comb_cut_df_copy.copy()\n",
    "    passed_df = passed_df.sort_values([\"LL\"],ascending=False).groupby(rse).head(1)\n",
    "    ts_mdf_pass[name] = passed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,6))\n",
    "\n",
    "xlo=-50\n",
    "xhi=0\n",
    "dx=0.25\n",
    "bins=np.arange(xlo,xhi+dx,dx)\n",
    "\n",
    "data = ts_mdf_pass['cosmic']['LL'].values\n",
    "weights = [1/float(data.size)]*data.size\n",
    "k1_res = ax.hist(data,bins=bins,weights=weights,color='red' ,histtype='stepfilled',alpha=0.1,lw=2)\n",
    "ax.hist(data,bins=bins,weights=weights,color='red' ,histtype='step',alpha=1.0,lw=2,label='Background')\n",
    "\n",
    "scedr=5\n",
    "SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1\"\n",
    "data = ts_mdf_pass['nue'].query(SS)['LL'].values\n",
    "weights = [1/float(data.size)]*data.size\n",
    "k0_res = ax.hist(data,bins=bins,weights=weights,color='blue',histtype='stepfilled',alpha=0.1,lw=2)\n",
    "ax.hist(data,bins=bins,weights=weights,color='blue',histtype='step',alpha=1.0,lw=2,label='Signal')\n",
    "\n",
    "ax.set_xlabel(\"Log Likelihood\",fontweight='bold')\n",
    "ax.set_ylabel(\"Fraction of Events\",fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k0_data = k0_res[0]\n",
    "k0_total = float(k0_data.sum())\n",
    "print \"sig LL total\",k0_total\n",
    "\n",
    "k1_data = k1_res[0]\n",
    "k1_total = float(k1_data.sum())\n",
    "print \"bkg LL total\",k1_total\n",
    "\n",
    "centers = bins + (bins[1]-bins[0])/2.0\n",
    "centers = centers[:-1]\n",
    "\n",
    "\n",
    "k0_sum  = [float(k0_data[ix:].sum()) for ix in xrange(centers.size)]\n",
    "k1_sum  = [float(k1_data[ix:].sum()) for ix in xrange(centers.size)]\n",
    "\n",
    "k01_sum = [k0_sum[ix] + k1_sum[ix] for ix in xrange(centers.size)]\n",
    "\n",
    "k0_eff  = [k0_sum[ix] / k0_total for ix in xrange(centers.size)]\n",
    "k1_eff  = [k1_sum[ix] / k1_total for ix in xrange(centers.size)]\n",
    "\n",
    "\n",
    "k0_sum  = np.array(k0_sum)\n",
    "k1_sum  = np.array(k1_sum)\n",
    "k01_sum = np.array(k01_sum)\n",
    "\n",
    "k0_eff = np.array(k0_eff)\n",
    "k1_eff = np.array(k1_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Efficiency\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,6))\n",
    "\n",
    "\n",
    "data = k1_eff * float(ts_mdf_m['cosmic'].index.size) / float(dfs['cosmic'].index.size)\n",
    "k1_rej = 1.0 - data\n",
    "ax.plot(centers,k1_rej,'-',color='red',lw=3,label='Background')\n",
    "ax.grid()\n",
    "\n",
    "scedr=5\n",
    "SS=\"scedr<@scedr & good_croi_ctr>0 & selected1L1P==1 & energyInit<800 & energyInit>200\"\n",
    "print float(ts_mdf_pass['nue'].query(SS).index.size)\n",
    "ratio = float(ts_mdf_pass['nue'].query(SS).index.size) / float(866.)\n",
    "data = k0_eff * ratio\n",
    "ax.plot(centers,data,'-',color='blue',lw=3,label='Signal')\n",
    "\n",
    "kk0 = np.where(k1_rej>0.995)[0][0]\n",
    "kk1 = np.where(k1_rej>0.999)[0][0]\n",
    "print\n",
    "print \"99.5\"\n",
    "print \"x  =\",centers[kk0]\n",
    "print \"y_c=\",k1_rej[kk0]\n",
    "print \"y_t=\",k0_eff[kk0]*ratio\n",
    "print\n",
    "print \"99.9\"\n",
    "print \"x  =\",centers[kk1]\n",
    "print \"y_c=\",k1_rej[kk1]\n",
    "print \"y_t=\",k0_eff[kk1]*ratio\n",
    "\n",
    "LLCUT = centers[kk0]\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Log Likelihood\",fontweight='bold')\n",
    "ax.set_ylabel(\"Efficiency\",fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim(0,1.0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ts_mdf_pass['cosmic'].query(\"LL>@LLCUT\").index.size\n",
    "print ts_mdf_pass['nue'].query(\"LL>@LLCUT & selected1L1P==1 & scedr<5\").index.size\n",
    "print ts_mdf_pass['nue'].query(\"LL>@LLCUT & selected1L1P==1 & scedr>5\").index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['font.size']=20\n",
    "matplotlib.rcParams['font.family']='serif'\n",
    "\n",
    "LLCUT=-14.625\n",
    "fix,ax=plt.subplots(figsize=(10,6))\n",
    "\n",
    "Xmin = 200\n",
    "Xmax = 800\n",
    "dX   = 50\n",
    "\n",
    "bins=np.arange(Xmin,Xmax + dX,dX)\n",
    "SS = 'selected1L1P==1 & good_croi_ctr>0'\n",
    "data=dfs['nue'].groupby(rse).nth(0).query(SS)['energyInit'].values\n",
    "ax.hist(data,bins=bins,color='red',histtype='stepfilled',alpha=0.1)\n",
    "sig = ax.hist(data,bins=bins,color='red',label='1L1P & Good cROI',histtype='step',lw=3)\n",
    "\n",
    "\n",
    "SS+= '& LL>=@LLCUT'\n",
    "data=ts_mdf_pass['nue'].query(SS)['energyInit'].values\n",
    "ax.hist(data,bins=bins,color='green',histtype='stepfilled',alpha=0.1)\n",
    "ax.hist(data,bins=bins,color='green',label='Pass Nue LL',histtype='step',lw=3)\n",
    "\n",
    "SS+= '& scedr<5'\n",
    "data=ts_mdf_pass['nue'].query(SS)['energyInit'].values\n",
    "ax.hist(data,bins=bins,color='blue',alpha=0.1,histtype='stepfilled')\n",
    "reco = ax.hist(data,bins=bins,color='blue',label='Pass Nue LL & Good Vertex',histtype='step',lw=3)\n",
    "\n",
    "ax.set_ylim(0,150)\n",
    "ax.set_xlim(200,800)\n",
    "ax.grid()\n",
    "ax.legend(loc='upper left',fontsize=18)\n",
    "\n",
    "ax.set_ylabel(\"Events\",fontweight='bold')\n",
    "ax.set_xlabel(\"True Neutrino Energy [MeV]\",fontweight='bold')\n",
    "plt.savefig(\"00_E.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots(figsize=(10,6))\n",
    "    \n",
    "reco_sig = reco[0] / sig[0]\n",
    "reco_sig = np.nan_to_num(reco_sig)\n",
    "bidx     = np.nonzero(reco_sig)\n",
    "signal_v = sig[0]\n",
    "param_v  = sig[1][:-1] + float(dX)/2.0\n",
    "eff_v    = reco_sig\n",
    "\n",
    "res_v     = np.where(eff_v==0)[0]\n",
    "eff_vv    = []\n",
    "signal_vv = []\n",
    "param_vv  = []\n",
    "eff_v_    = []\n",
    "signal_v_ = []\n",
    "param_v_  = []\n",
    "\n",
    "\n",
    "for ix in xrange(eff_v.size):\n",
    "    if ix in res_v:\n",
    "        eff_vv.append(np.array(eff_v_))\n",
    "        signal_vv.append(np.array(signal_v_))\n",
    "        param_vv.append(np.array(param_v_))\n",
    "        eff_v_    = []\n",
    "        signal_v_ = []\n",
    "        param_v_  = []\n",
    "        continue\n",
    "\n",
    "    eff_v_.append(eff_v[ix])\n",
    "    signal_v_.append(signal_v[ix])\n",
    "    param_v_.append(param_v[ix])\n",
    "\n",
    "eff_vv.append(np.array(eff_v_))\n",
    "signal_vv.append(np.array(signal_v_))\n",
    "param_vv.append(np.array(param_v_))\n",
    "\n",
    "for param_v_,eff_v_,signal_v_ in zip(param_vv,eff_vv,signal_vv):\n",
    "    ax.plot(param_v_,eff_v_,'o',color='blue',markersize=8)\n",
    "    ax.errorbar(param_v_,eff_v_,yerr= np.sqrt( eff_v_ * ( 1 - eff_v_ ) / signal_v_ ),lw=2,color='blue')\n",
    "\n",
    "ax.set_ylabel(\"Reco. Efficiency\",fontweight='bold')\n",
    "ax.set_xlabel(\"True Neutrino Energy [MeV]\",fontweight='bold')\n",
    "ax.set_ylim(0,1.0)\n",
    "plt.grid()\n",
    "plt.savefig(\"00_eff.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLCUT=-18.25\n",
    "plt.hist(ts_mdf_pass['nue'].query(\"LL>=@LLCUT\").LL.values)\n",
    "plt.show()\n",
    "plt.hist(ts_mdf_pass['cosmic'].query(\"LL>=@LLCUT\").LL.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print\n",
    "print \"cosmic\"\n",
    "fout = open(\"these_cosmic.sh\",\"w+\")\n",
    "for run,subrun,event in ts_mdf_pass['cosmic'].query(\"LL>=@LLCUT\")[['run','subrun','event']].values:\n",
    "    rse = (run,subrun,event)\n",
    "    fout.write(\"python dump_img.py\")\n",
    "    fout.write(\" \")\n",
    "    f=os.path.basename(res.set_index(['run','subrun','event']).loc[rse].fname)\n",
    "    fout.write(os.path.join(\"cosmic_in\",f))\n",
    "    fout.write(\" \")\n",
    "    num = int(f.split(\".\")[0].split(\"_\")[-1])\n",
    "    fout.write(os.path.join(\"cosmic_out\",\"out_%d.root\" % num))\n",
    "    fout.write(\" \")\n",
    "    erv = ts_mdf_pass['cosmic'].set_index(['run','subrun','event']).loc[rse][['entry','roid','cvtxid']].values\n",
    "    fout.write(\"%d %d %d &\" %(erv[0],erv[1],erv[2]))\n",
    "    fout.write(\"\\n\")\n",
    "    print rse,\"\\t\",f,\"%d %d %d &\" %(erv[0],erv[1],erv[2])\n",
    "    \n",
    "fout.close()\n",
    "print\n",
    "print \"nue\"\n",
    "fout = open(\"these_nue.sh\",\"w+\")\n",
    "for run,subrun,event in ts_mdf_pass['nue'].query(\"LL>=@LLCUT & scedr>5 & selected1L1P==1 & energyInit>200 & energyInit<800\")[['run','subrun','event']].values:\n",
    "    rse = (run,subrun,event)\n",
    "    fout.write(\"python dump_img.py\")\n",
    "    fout.write(\" \")\n",
    "    f=os.path.basename(res_nue.set_index(['run','subrun','event']).loc[rse].fname)\n",
    "    print rse,\"\\t\",f\n",
    "    fout.write(os.path.join(\"nue_in\",f))\n",
    "    fout.write(\" \")\n",
    "    num = int(f.split(\".\")[0].split(\"_\")[-1])\n",
    "    fout.write(os.path.join(\"nue_out\",\"out_%d.root\" % num))\n",
    "    fout.write(\" \")\n",
    "    erv = ts_mdf_pass['nue'].set_index(['run','subrun','event']).loc[rse][['entry','roid','cvtxid']].values\n",
    "    fout.write(\"%d %d %d &\" %(erv[0],erv[1],erv[2]))\n",
    "    fout.write(\"\\n\")\n",
    "fout.close()\n",
    "\n",
    "rse=['run','subrun','event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(rn.root2array(\"comb_trk_cosmic.root\",treename=\"EventCosmicTrackTree\"))\n",
    "rse=['run','subrun','event']\n",
    "res = res.set_index(rse)\n",
    "print list(res.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nue_group = dfs['nue'].groupby(rse).nth(0).query(\"selected1L1P==1\")\n",
    "print nue_group.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_comb = pd.concat([nue_group,res],axis=1,join_axes=[nue_group.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### matplotlib.rcParams['font.size']=20\n",
    "for thing in ['n_top_pts', 'n_bot_pts', 'n_up_pts', 'n_down_pts', 'n_anode_pts', 'n_cathode_pts',\n",
    "              'num_croi',\n",
    "              'n_thru_mu_trk', 'n_stop_mu_trk',\n",
    "              'num_vertex']:\n",
    "    if thing != 'n_top_pts':\n",
    "        continue\n",
    "    print thing\n",
    "    data0 = np.nan_to_num(res_comb[thing].values)\n",
    "    data1 = np.nan_to_num(res_comb.query(\"min_vtx_dist<5 & num_vertex>0\")[thing].values)\n",
    "    data2 = np.nan_to_num(res_comb.query(\"min_vtx_dist>5 & num_vertex>0\")[thing].values)\n",
    "    bins = np.arange(0,102,2)\n",
    "    weights0=[1/float(res_comb.index.size)] * data0.size\n",
    "    #weights1=[1/float(res_comb.index.size)] * data1.size\n",
    "    #weights2=[1/float(res_comb.index.size)] * data2.size\n",
    "    \n",
    "    weights1=[1/float(data1.size)] * data1.size\n",
    "    weights2=[1/float(data2.size)] * data2.size\n",
    "    \n",
    "    #plt.hist(data0,bins=bins,weights=weights0,color='red',histtype='stepfilled',alpha=0.1,lw=3)\n",
    "    plt.hist(data1,bins=bins,weights=weights1,color='blue',histtype='stepfilled',alpha=0.1,lw=3)\n",
    "    plt.hist(data2,bins=bins,weights=weights2,color='green',histtype='stepfilled',alpha=0.1,lw=3)\n",
    "    \n",
    "    #plt.hist(data0,bins=bins,weights=weights0,color='red',histtype='step',alpha=1.0,label=\"all\",lw=3)\n",
    "    plt.hist(data1,bins=bins,weights=weights1,color='blue',histtype='step',alpha=1.0,label=\"good\",lw=3)\n",
    "    plt.hist(data2,bins=bins,weights=weights2,color='green',histtype='step',alpha=1.0,label=\"bad\",lw=3)\n",
    "    \n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(10,6)\n",
    "\n",
    "    ax=plt.gca()\n",
    "    ax.set_xlabel(\"Number of Top Piercing\",fontweight='bold')\n",
    "    ax.set_ylabel(\"Event Fraction\\n1e1p with 1L1P Filter\",fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "    ax=plt.gca()\n",
    "    ax.set_xlim(0,40)\n",
    "    plt.savefig(\"/home/vgenty/{}_png\".format(thing))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(rn.root2array(\"comb_trk_cosmic_extbnb.root\",treename=\"EventCosmicTrackTree\"))\n",
    "rse=['run','subrun','event']\n",
    "res = res.set_index(rse)\n",
    "\n",
    "cosmic_group = dfs['cosmic'].groupby(rse).nth(0)\n",
    "print cosmic_group.index.size\n",
    "\n",
    "res_comb = pd.concat([cosmic_group,res],axis=1,join_axes=[cosmic_group.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['font.size']=20\n",
    "for thing in ['n_top_pts', 'n_bot_pts', 'n_up_pts', 'n_down_pts', 'n_anode_pts', 'n_cathode_pts',\n",
    "              'num_croi',\n",
    "              'n_thru_mu_trk', 'n_stop_mu_trk',\n",
    "              'num_vertex']:\n",
    "    print thing\n",
    "    #data0 = np.nan_to_num(res_comb[thing].values)\n",
    "    data1 = np.nan_to_num(res_comb.query(\"num_vertex>0\")[thing].values)\n",
    "    bins = np.arange(0,102,2)\n",
    "    #weights0=[1/float(res_comb.index.size)] * data0.size\n",
    "    weights1=[1/float(res_comb.index.size)] * data1.size\n",
    "    \n",
    "    plt.hist(data1,bins=bins,weights=weights1,color='blue',histtype='stepfilled',alpha=0.1,lw=3)\n",
    "    #plt.hist(data0,bins=bins,weights=weights0,color='red',histtype='stepfilled',alpha=0.1,lw=3)\n",
    "    \n",
    "    plt.hist(data1,bins=bins,weights=weights1,color='blue',histtype='step',alpha=1.0,label=\"...\",lw=3)\n",
    "    #plt.hist(data0,bins=bins,weights=weights0,color='red',histtype='step',alpha=1.0,label=\"all\",lw=3)\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(10,6)\n",
    "    ax=plt.gca()\n",
    "    ax.set_xlabel(thing,fontweight='bold')\n",
    "    ax.set_ylabel(\"Event Fraction\",fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"{}_png\".format(thing))\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mdf_pass['nue'].query(\"LL>@LLCUT \").index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
